<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Supervised Mixture-of-Experts for Surgical Grasping and Retraction using lightweight action transformers.">
  <meta name="keywords" content="Surgical Robotics, Imitation Learning, Mixture of Experts, ACT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Supervised Mixture-of-Experts for Surgical Grasping and Retraction</title>

  <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg" type="image/svg+xml">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    :root {
      --dark: #1a1a2e;
      --dark-mid: #16213e;
      --dark-surface: #1e2a42;
      --accent-red: #e94560;
      --accent-red-light: rgba(233, 69, 96, 0.12);
      --accent-blue: #4a90d9;
      --accent-green: #1fab89;
      --accent-gold: #f5c542;
      --text-primary: #e8e8f0;
      --text-secondary: #9a9ab8;
      --text-muted: #6a6a88;
      --border: rgba(255,255,255,0.06);
      --glass: rgba(30, 42, 66, 0.7);
    }

    * { box-sizing: border-box; }

    body {
      font-family: 'DM Sans', sans-serif;
      background: var(--dark);
      color: var(--text-primary);
    }

    /* ---- Navbar ---- */
    .navbar {
      background: rgba(26, 26, 46, 0.9);
      backdrop-filter: blur(12px);
      border-bottom: 1px solid var(--border);
    }
    .navbar-item { color: var(--text-secondary); }
    .navbar-item:hover { color: var(--text-primary); background: transparent; }

    /* ---- Hero ---- */
    .hero-section {
      background: linear-gradient(180deg, var(--dark) 0%, var(--dark-mid) 100%);
      padding: 5rem 1.5rem 3rem;
      position: relative;
      overflow: hidden;
    }

    .hero-section::before {
      content: '';
      position: absolute;
      top: -200px;
      right: -200px;
      width: 600px;
      height: 600px;
      background: radial-gradient(circle, rgba(233,69,96,0.06) 0%, transparent 70%);
      pointer-events: none;
    }

    .hero-section::after {
      content: '';
      position: absolute;
      bottom: -150px;
      left: -150px;
      width: 500px;
      height: 500px;
      background: radial-gradient(circle, rgba(31,171,137,0.05) 0%, transparent 70%);
      pointer-events: none;
    }

    .publication-title {
      font-family: 'DM Sans', sans-serif;
      font-weight: 700;
      color: var(--text-primary);
      font-size: 2.6rem !important;
      line-height: 1.2;
      letter-spacing: -0.02em;
    }

    .publication-authors {
      color: var(--text-secondary);
      font-style: italic;
      margin-top: 1rem;
    }

    .publication-links {
      margin-top: 1.5rem;
    }

    .publication-links .button {
      margin: 4px;
      background: var(--dark-surface);
      border: 1px solid var(--border);
      color: var(--text-primary);
      font-family: 'DM Sans', sans-serif;
      font-weight: 500;
      transition: all 0.2s ease;
    }

    .publication-links .button:hover {
      background: var(--accent-red);
      border-color: var(--accent-red);
      color: white;
    }

    .publication-links .button .icon {
      color: var(--text-secondary);
    }

    .publication-links .button:hover .icon {
      color: white;
    }

    /* ---- Teaser ---- */
    .teaser-section {
      background: var(--dark-mid);
      padding: 2rem 1.5rem 3rem;
    }

    .teaser-section video {
      border-radius: 10px;
      border: 1px solid var(--border);
    }

    .teaser-subtitle {
      color: var(--text-secondary);
      font-size: 1.05rem;
      margin-top: 1.5rem;
      line-height: 1.7;
    }

    .teaser-subtitle strong {
      color: var(--accent-red);
    }

    /* ---- Sections ---- */
    .section {
      background: var(--dark);
      padding: 4rem 1.5rem;
    }

    .section.alt-bg {
      background: var(--dark-mid);
    }

    .section-divider {
      width: 50px;
      height: 3px;
      background: var(--accent-red);
      margin: 0 auto 2rem;
      border-radius: 2px;
    }

    h2.title.is-3 {
      font-family: 'DM Sans', sans-serif;
      color: var(--text-primary);
      font-weight: 700;
      font-size: 1.75rem;
      letter-spacing: -0.01em;
    }

    h3.title.is-4 {
      font-family: 'DM Sans', sans-serif;
      color: var(--text-primary);
      font-weight: 600;
    }

    .content p {
      color: var(--text-secondary);
      line-height: 1.8;
    }

    .content strong {
      color: var(--accent-red);
      font-weight: 600;
    }

    /* ---- Method figure ---- */
    .method-img-wrapper {
      background: var(--dark-surface);
      border-radius: 12px;
      padding: 1.5rem;
      border: 1px solid var(--border);
      margin-bottom: 1.5rem;
    }

    .method-img-wrapper img {
      width: 100%;
      border-radius: 8px;
    }

    /* ---- Video comparison grid ---- */
    .comparison-label {
      display: inline-block;
      padding: 4px 14px;
      border-radius: 20px;
      font-size: 0.78rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.06em;
      margin-bottom: 0.5rem;
    }

    .label-baseline {
      background: rgba(74, 144, 217, 0.15);
      color: var(--accent-blue);
    }

    .label-ours {
      background: rgba(31, 171, 137, 0.15);
      color: var(--accent-green);
    }

    .label-vla {
      background: rgba(233, 69, 96, 0.12);
      color: var(--accent-red);
    }

    .label-ood {
      background: rgba(245, 197, 66, 0.15);
      color: var(--accent-gold);
    }

    .video-card {
      background: var(--dark-surface);
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid var(--border);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      margin-bottom: 1.5rem;
    }

    .video-card:hover {
      transform: translateY(-3px);
      box-shadow: 0 12px 40px rgba(0,0,0,0.3);
    }

    .video-card video {
      width: 100%;
      display: block;
    }

    .video-card .card-info {
      padding: 1rem 1.25rem;
    }

    .video-card .card-info h4 {
      font-family: 'DM Sans', sans-serif;
      font-weight: 600;
      font-size: 1rem;
      color: var(--text-primary);
      margin-bottom: 0.25rem;
    }

    .video-card .card-info p {
      font-size: 0.88rem;
      color: var(--text-muted);
      line-height: 1.5;
    }

    /* ---- Results stat bar ---- */
    .stat-bar {
      display: flex;
      gap: 1.5rem;
      justify-content: center;
      flex-wrap: wrap;
      margin: 2rem 0 3rem;
    }

    .stat-card {
      background: var(--dark-surface);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 1.5rem 2rem;
      text-align: center;
      min-width: 180px;
      transition: border-color 0.3s;
    }

    .stat-card:hover {
      border-color: var(--accent-red);
    }

    .stat-card .stat-value {
      font-family: 'DM Sans', sans-serif;
      font-size: 2rem;
      font-weight: 700;
      color: var(--accent-red);
    }

    .stat-card .stat-label {
      font-size: 0.82rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-top: 0.3rem;
    }

    /* ---- Transfer section highlight ---- */
    .transfer-highlight {
      background: linear-gradient(135deg, rgba(31,171,137,0.08) 0%, rgba(233,69,96,0.05) 100%);
      border: 1px solid rgba(31,171,137,0.15);
      border-radius: 16px;
      padding: 2.5rem;
      margin: 2rem 0;
    }

    .transfer-highlight h3 {
      color: var(--accent-green) !important;
    }

    /* ---- In vivo banner ---- */
    .invivo-banner {
      background: linear-gradient(135deg, rgba(233,69,96,0.08) 0%, rgba(245,197,66,0.05) 100%);
      border: 1px solid rgba(233,69,96,0.15);
      border-radius: 16px;
      padding: 2.5rem;
      margin: 2rem 0;
    }

    .invivo-banner h3 {
      color: var(--accent-red) !important;
    }

    /* ---- BibTeX ---- */
    .bibtex-section pre {
      background: var(--dark-surface);
      color: var(--accent-green);
      border-radius: 10px;
      padding: 1.5rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      line-height: 1.6;
      border: 1px solid var(--border);
      overflow-x: auto;
    }

    /* ---- Footer ---- */
    .footer {
      background: var(--dark-mid);
      border-top: 1px solid var(--border);
      padding: 2rem 1.5rem;
    }
    .footer p, .footer a {
      color: var(--text-muted);
      font-size: 0.85rem;
    }
    .footer a:hover { color: var(--text-secondary); }

    /* ---- Utilities ---- */
    .has-text-justified { text-align: justify; }

    .subsection-title {
      font-family: 'DM Sans', sans-serif;
      font-weight: 600;
      font-size: 1.15rem;
      color: var(--text-primary);
      text-align: center;
      margin: 3rem 0 1rem;
    }

    .subsection-desc {
      text-align: center;
      color: var(--text-muted);
      margin-bottom: 1.5rem;
      font-size: 0.95rem;
    }

    @media (max-width: 768px) {
      .publication-title { font-size: 1.6rem !important; }
      .stat-bar { flex-direction: column; align-items: center; }
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
        <span class="icon"><i class="fas fa-home"></i></span>
      </a>
    </div>
  </div>
</nav>

<!-- Hero -->
<section class="hero-section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h1 class="title is-1 publication-title">
          Supervised Mixture-of-Experts for Surgical Grasping and Retraction
        </h1>

        <div class="is-size-5 publication-authors">
          Author names omitted for anonymous review
        </div>

        <div class="publication-links">
          <span class="link-block">
            <a href="LINK_TO_PDF" class="external-link button is-normal is-rounded">
              <span class="icon"><i class="fas fa-file-pdf"></i></span>
              <span>Paper</span>
            </a>
          </span>
          <span class="link-block">
            <a href="LINK_TO_ARXIV" class="external-link button is-normal is-rounded">
              <span class="icon"><i class="ai ai-arxiv"></i></span>
              <span>arXiv</span>
            </a>
          </span>
          <span class="link-block">
            <a href="LINK_TO_YOUTUBE" class="external-link button is-normal is-rounded">
              <span class="icon"><i class="fab fa-youtube"></i></span>
              <span>Video</span>
            </a>
          </span>
          <span class="link-block">
            <a href="LINK_TO_GITHUB" class="external-link button is-normal is-rounded">
              <span class="icon"><i class="fab fa-github"></i></span>
              <span>Code</span>
            </a>
          </span>
          <span class="link-block">
            <a href="LINK_TO_GITHUB" class="external-link button is-normal is-rounded">
              <span class="icon"><i class="fas fa-database"></i></span>
              <span>Dataset</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Videos -->
<section class="teaser-section">
  <div class="container is-fluid" style="max-width:1400px;">
    <div class="columns is-centered">
      <div class="column">
        <video autoplay muted loop playsinline width="100%">
          <source src="./static/videos/phantom_cover.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column">
        <video autoplay muted loop playsinline width="100%">
          <source src="./static/videos/ex_vivo_cover.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column">
        <video autoplay muted loop playsinline width="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    <p class="teaser-subtitle has-text-centered">
      Our <strong>Supervised MoE</strong> policy performing autonomous surgical bowel grasping and retraction
      using <strong>only stereo endoscopic camera feed</strong> as input — across phantom, <em>ex vivo</em>, and <em>in vivo</em>.
    </p>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="section-divider"></div>
        <div class="content has-text-justified">
          <p>
            Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability.
          </p>
          <p>
            We present a supervised <strong>Mixture-of-Experts (MoE)</strong> architecture designed for phase-structured surgical manipulation tasks. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from only <strong>150 demonstrations</strong> using solely stereo endoscopic images, when equipped with our architecture.
          </p>
          <p>
            We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction.
          </p>
          <p>
            We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that <strong>generalist VLAs fail to acquire the task entirely</strong>, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting the Supervised MoE architecture <strong>significantly boosts its performance</strong>, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions.
            Notably, it <strong>generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue</strong> without additional training, offering a promising pathway toward in vivo deployment. To support this statement, we present qualitative preliminary results of policy roll-outs during <strong>in vivo porcine surgery</strong>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Key Stats -->
<section class="section alt-bg">
  <div class="container is-max-desktop">
    <div class="stat-bar">
      <div class="stat-card">
        <div class="stat-value">120</div>
        <div class="stat-label">Demonstrations</div>
      </div>
      <div class="stat-card">
        <div class="stat-value">53M</div>
        <div class="stat-label">Parameters (ACT+MoE)</div>
      </div>
      <div class="stat-card">
        <div class="stat-value">80%</div>
        <div class="stat-label">Zero-shot ex vivo transfer</div>
      </div>
      <div class="stat-card">
        <div class="stat-value">0</div>
        <div class="stat-label">VLA task completions</div>
      </div>
    </div>
  </div>
</section>

<!-- Method -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="section-divider"></div>
        <div class="method-img-wrapper">
          <img src="./static/images/model_architecture.png" alt="MoE Architecture">
        </div>
        <div class="content has-text-justified">
          <p>
            We integrate a Phase-Aware Mixture-of-Experts (MoE) block into a standard transformer policy.
            The block consists of <strong>H parallel experts</strong> (one for each phase of the surgery) and a gating network.
            The gating network is supervised with phase labels during training, ensuring that the correct expert
            specializes in the correct sub-task (e.g., Grasping vs. Retracting).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- In-Distribution Comparison -->
<section class="section alt-bg">
  <div class="container is-max-widescreen">
    <h2 class="title is-3 has-text-centered">In-Distribution Comparison</h2>
    <div class="section-divider"></div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/smolvla.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-vla">VLA</span>
            <h4>SmolVLA</h4>
            <p>Unsafe — pushes against the bowel</p>
          </div>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/pi05.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-vla">VLA</span>
            <h4>&pi;0.5</h4>
            <p>Does not commit to a phase</p>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/act.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-baseline">Baseline</span>
            <h4>ACT</h4>
            <p>Poor grasping, leading to slippage</p>
          </div>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card" style="border-color: rgba(31,171,137,0.3);">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/phantom_moe_indistribution.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-ours">Ours</span>
            <h4>ACT + Supervised MoE</h4>
            <p>Successfully executes the full task</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Out-of-Distribution -->
<section class="section">
  <div class="container is-max-widescreen">
    <h2 class="title is-3 has-text-centered">Out-of-Distribution Generalization</h2>
    <div class="section-divider"></div>
    <p class="subsection-desc">
      Our model generalizes to unseen scenarios without additional training.
    </p>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/ood_1.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-ood">OOD</span>
            <h4>Unseen Bowel Segment</h4>
          </div>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/ood_2.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-ood">OOD</span>
            <h4>Different Lighting</h4>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/ood_3.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-ood">OOD</span>
            <h4>Bowel Occlusion</h4>
          </div>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/ood_4.mp4" type="video/mp4">
          </video>
          <div class="card-info">
            <span class="comparison-label label-ood">OOD</span>
            <h4>Unseen Viewpoint</h4>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Viewpoint Randomization -->
<section class="section alt-bg">
  <div class="container is-max-widescreen">
    <h2 class="title is-3 has-text-centered">Viewpoint Randomization</h2>
    <div class="section-divider"></div>
    <p class="subsection-desc">
      Retraining with randomized camera viewpoints further improves robustness to viewpoint variations.
    </p>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/rv_1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/rv_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/rv_3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column is-half">
        <div class="video-card">
          <video autoplay controls muted loop playsinline>
            <source src="./static/videos/rv_4.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Zero-Shot Transfer -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="transfer-highlight">
      <h3 class="title is-3 has-text-centered">Zero-Shot Transfer to Ex Vivo Tissue</h3>
      <div class="section-divider" style="background: var(--accent-green);"></div>
      <div class="content has-text-justified">
        <p>
          We tested the policy (trained only on phantom data) directly on <strong style="color: var(--accent-green);">ex vivo porcine tissue</strong> without any fine-tuning.
          The policy achieved an <strong style="color: var(--accent-green);">80% success rate</strong>, demonstrating robust generalization to real tissue appearance and deformation.
        </p>
      </div>
      <div class="has-text-centered">
        <video autoplay controls muted loop playsinline width="90%" style="border-radius:10px; border:1px solid rgba(31,171,137,0.2);">
          <source src="./static/videos/ex_vivo.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<!-- In Vivo -->
<section class="section alt-bg">
  <div class="container is-max-desktop">
    <div class="invivo-banner">
      <h3 class="title is-3 has-text-centered">Preliminary In Vivo Results</h3>
      <div class="section-divider"></div>
      <div class="content has-text-justified" style="margin-bottom:1.5rem;">
        <p>
          Qualitative policy roll-outs during live porcine surgery, demonstrating a pathway toward clinical deployment.
        </p>
      </div>
      <div class="has-text-centered" style="margin-bottom:1.5rem;">
        <video autoplay controls muted loop playsinline width="100%" style="border-radius:10px; border:1px solid rgba(233,69,96,0.2);">
          <source src="./static/videos/invivo_3.mp4" type="video/mp4">
        </video>
      </div>
      <div class="has-text-centered">
        <video autoplay controls muted loop playsinline width="100%" style="border-radius:10px; border:1px solid rgba(233,69,96,0.2);">
          <source src="./static/videos/invivo_1.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <div class="section-divider"></div>
    <div class="bibtex-section">
      <pre><code>@article{Anonymous2026SurgicalMoE,
  author    = {Anonymous Authors},
  title     = {Supervised Mixture-of-Experts for Surgical
               Grasping and Retraction},
  year      = {2026},
}</code></pre>
    </div>
  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Adapted from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> template,
            licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>